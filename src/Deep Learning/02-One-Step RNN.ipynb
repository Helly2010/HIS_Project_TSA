{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25018c9-2624-434c-aa23-04be1d73e729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\Project\\Modern-Time-Series-Forecasting-with-Python-main\\Modern-Time-Series-Forecasting-with-Python-main\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f023467-970a-461e-a60f-7a66fce6a497",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\Project\\Modern-Time-Series-Forecasting-with-Python-main\\Modern-Time-Series-Forecasting-with-Python-main\\src\\utils\\data_utils.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.forecasting.ml_forecasting import (\n",
    "    MissingValueConfig,\n",
    "    calculate_metrics,\n",
    ")\n",
    "from src.utils import plotting_utils\n",
    "from tqdm.autonotebook import tqdm\n",
    "from src.forecasting.ml_forecasting import calculate_metrics\n",
    "from src.utils import ts_utils\n",
    "from IPython.display import display, HTML\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "np.random.seed(42)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ae72a1-3721-4b36-b211-b78d4b09c855",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_13\", exist_ok=True)\n",
    "preprocessed = Path(\"data/london_smart_meters/preprocessed\")\n",
    "output = Path(\"data/london_smart_meters/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee3229-29b1-41ea-a4f0-25237abd617a",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8900cd43-718f-4dc1-ace9-ef9dc99b600d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.98,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad04560f-5130-437f-83b0-9929adf63f37",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def plot_forecast(pred_df, forecast_columns, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns) == len(forecast_display_names)\n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    colors = [\n",
    "        \"rgba(\" + \",\".join([str(c) for c in plotting_utils.hex_to_rgb(c)]) + \",<alpha>)\"\n",
    "        for c in px.colors.qualitative.Plotly\n",
    "    ]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pred_df[mask].index,\n",
    "            y=pred_df[mask].energy_consumption,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=act_color.replace(\"<alpha>\", \"0.9\")),\n",
    "            name=\"Actual Consumption\",\n",
    "        )\n",
    "    )\n",
    "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pred_df[mask].index,\n",
    "                y=pred_df.loc[mask, col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(dash=\"dot\", color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                name=display_col,\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s == np.nanmin(np.abs(s.values)), props, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5c5f4-29e5-4a80-825f-83eb976c5eb3",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a45da0-76e2-46ed-9eef-5cd1a1b5623c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(\"C:\\\\Users\\\\anike\\\\Project\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Data\\\\london_smart_meters\\\\Preprocessed\\\\selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    \n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(\"C:\\\\Users\\\\anike\\\\Project\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Data\\\\london_smart_meters\\\\Preprocessed\\\\selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"block_0-7_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe10433-e8a0-490d-a476-54ef6b73240a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = \"energy_consumption\"\n",
    "index_cols = [\"LCLid\", \"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd73612f-5cfc-4331-bf7f-158f5a77251e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting the indices\n",
    "train_df.set_index(index_cols, inplace=True, drop=False)\n",
    "test_df.set_index(index_cols, inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dac12a-86d0-44eb-8497-c94f0cf51dbf",
   "metadata": {},
   "source": [
    "### Loading the Single Step ML Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1be72a3-0a54-4444-88fa-740ea826d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    single_step_ahead_ml_fc_df = pd.read_pickle(\"C:\\\\Users\\\\anike\\\\Project\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Data\\\\london_smart_meters\\\\Preprocessed\\\\output\\\\ml_single_step_prediction_val_df.pkl\")\n",
    "    single_step_ahead_ml_metrics_df = pd.read_pickle(\"C:\\\\Users\\\\anike\\\\Project\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Data\\\\london_smart_meters\\\\Preprocessed\\\\output\\\\ml_single_step_metrics_val_df.pkl\")\n",
    "    single_step_ahead_ml_agg_metrics_df = pd.read_pickle(\"C:\\\\Users\\\\anike\\\\Project\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Modern-Time-Series-Forecasting-with-Python-main\\\\Data\\\\london_smart_meters\\\\Preprocessed\\\\output\\\\ml_single_step_aggregate_metrics_val.pkl\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Forecasting with ML in Chapter08\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a785ca6-9eb3-4aff-88c5-18816959ceb3",
   "metadata": {},
   "source": [
    "# Running the RNN on a Sample Household"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f54fe6c-0206-47ce-b444-d1ca5c3bfe96",
   "metadata": {},
   "source": [
    "## Selecting the sample data and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b2bac1-0add-4a72-9782-7b765d46fe0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_train_df = train_df.xs(\"MAC000193\")\n",
    "sample_test_df = test_df.xs(\"MAC000193\")\n",
    "# Creating a pred_df with actuals\n",
    "pred_df = pd.concat([sample_train_df[[target]], sample_test_df[[target]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3681d085-257d-4b6d-8e08-cc3e74432576",
   "metadata": {},
   "source": [
    "Split Train into Train and Validation and combine everything together into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99929314-f0e7-4124-bcdd-6f7f6905e420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>0.368</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:30:00</th>\n",
       "      <td>0.386</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>0.170</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:30:00</th>\n",
       "      <td>0.021</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>0.038</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     energy_consumption   type\n",
       "timestamp                                     \n",
       "2012-01-01 00:00:00               0.368  train\n",
       "2012-01-01 00:30:00               0.386  train\n",
       "2012-01-01 01:00:00               0.170  train\n",
       "2012-01-01 01:30:00               0.021  train\n",
       "2012-01-01 02:00:00               0.038  train"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_val_df = sample_train_df.loc[\"2013-12\"]\n",
    "sample_train_df = sample_train_df.loc[:\"2013-11\"]\n",
    "\n",
    "sample_train_df['type'] = \"train\"\n",
    "sample_val_df['type'] = \"val\"\n",
    "sample_test_df['type'] = \"test\"\n",
    "sample_df = pd.concat([sample_train_df[[target, \"type\"]], sample_val_df[[target, \"type\"]], sample_test_df[[target, \"type\"]]])\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0eb4b4-eb24-4667-b24c-28a9e09f66d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Algorithm': 'Lasso Regression',\n",
       "  'MAE': 0.1597835027624957,\n",
       "  'MSE': 0.0743109727658381,\n",
       "  'MASE': 1.2452205596399155,\n",
       "  'Forecast Bias': 3.764424250786792},\n",
       " {'Algorithm': 'XGB Random Forest',\n",
       "  'MAE': 0.16420233249664307,\n",
       "  'MSE': 0.08141842484474182,\n",
       "  'MASE': 1.2796571254730225,\n",
       "  'Forecast Bias': 8.940213918685913},\n",
       " {'Algorithm': 'LightGBM',\n",
       "  'MAE': 0.14886508634822698,\n",
       "  'MSE': 0.06913165778511937,\n",
       "  'MASE': 1.1601314461663779,\n",
       "  'Forecast Bias': 3.862088397030192}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_record = []\n",
    "metric_record += (\n",
    "    single_step_ahead_ml_metrics_df.loc[single_step_ahead_ml_metrics_df.LCLid == \"MAC000193\"]\n",
    "    .drop(columns=\"LCLid\")\n",
    "    .to_dict(orient=\"records\")\n",
    ")\n",
    "metric_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556be25d-d682-4e11-9745-35694cb04f63",
   "metadata": {},
   "source": [
    "## Loading the necessary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19dc2414-c2dd-434c-928e-0f5580ca9af0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dl.dataloaders import TimeSeriesDataModule\n",
    "from src.dl.models import SingleStepRNNConfig, SingleStepRNNModel\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "# For reproduceability set a random seed\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd6990b-32da-4d7d-bb37-a16ee772b9fc",
   "metadata": {},
   "source": [
    "### Creating the datamodule which splits and formats the data into windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81f7e11-4f77-4eb3-804e-2135ad331f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datamodule = TimeSeriesDataModule(data = sample_df[[target]],\n",
    "        n_val = sample_val_df.shape[0],\n",
    "        n_test = sample_test_df.shape[0],\n",
    "        window = 48, # giving enough memory to capture daily seasonality\n",
    "        horizon = 1, # single step\n",
    "        normalize = \"global\", # normalizing the data\n",
    "        batch_size = 32,\n",
    "        num_workers = 0)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133082a-1843-4058-99e3-7ea2bc9e0b7c",
   "metadata": {},
   "source": [
    "### Setting the config for the RNN and initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc511908-f8a0-4d64-9288-cc3dcb3fdca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn_config = SingleStepRNNConfig(\n",
    "    rnn_type=\"RNN\",\n",
    "    input_size=1,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    bidirectional=True,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "model = SingleStepRNNModel(rnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652dc53-8242-4539-b1f0-e2385bfcc331",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Manual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8ba6a7d-439c-4d9f-ab5b-ef55e0bd24dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x:  torch.Size([32, 48, 1])\n",
      "Shape of y:  torch.Size([32, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Getting a batch from the train_dataloader\n",
    "for batch in datamodule.train_dataloader():\n",
    "    x, y = batch\n",
    "    break\n",
    "print(\"Shape of x: \",x.shape)\n",
    "print(\"Shape of y: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b36d992-e3fb-4afa-a9f8-c34e3d21c648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_hat:  torch.Size([32, 48, 1])\n",
      "Shape of y:  torch.Size([32, 48, 1])\n"
     ]
    }
   ],
   "source": [
    "# Running the batch through the model\n",
    "# We expect two outputs - the first one is the forecast and second is the corresponding target\n",
    "y_hat, y = model(batch)\n",
    "print(\"Shape of y_hat: \",y_hat.shape)\n",
    "print(\"Shape of y: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4221f36-284f-4d19-b715-26f6e8c284fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9786, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculating the loss\n",
    "l = model.loss(y_hat, y)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7167f-54f7-40a8-946a-01aa061ff726",
   "metadata": {},
   "source": [
    "### Full Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966323c0-2be1-4823-b9af-91cde0e309eb",
   "metadata": {},
   "source": [
    "**Uncomment below cell if you need to monitor training using TensorBoard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "438a1a61-9397-4580-a254-58bb40e0811a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "# os.makedirs(lightning_logs, exist_ok=True)\n",
    "# %tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c99930b-f435-41e8-92ce-cc007c501e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type    | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | rnn  | RNN     | 231 K  | train\n",
      "1 | fc   | Linear  | 257    | train\n",
      "2 | loss | MSELoss | 0      | train\n",
      "-----------------------------------------\n",
      "231 K     Trainable params\n",
      "0         Non-trainable params\n",
      "231 K     Total params\n",
      "0.926     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b0e2e12b854787ba41e32ceaac3694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(        # Enables GPU acceleration\n",
    "    devices=\"auto\",           # Automatically uses all available GPUs\n",
    "    min_epochs=1,\n",
    "    max_epochs=1,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor=\"valid_loss\", patience=3)],\n",
    ")\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81adb94-d1a2-47ef-8fdd-1cc2557c9d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing artifacts created during training\n",
    "shutil.rmtree(\"lightning_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed4d5a-7566-40eb-9b49-7eb7548d0aa5",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bafde2af-a017-4c40-a3d5-ff3928be9fbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac155ee2f9f41fab6b55765d0b8cb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(model, datamodule.test_dataloader())\n",
    "# pred is a list of outputs, one for each batch\n",
    "pred = torch.cat(pred).squeeze().detach().numpy()\n",
    "# Apply reverse transformation because we applied global normalization\n",
    "pred = pred * datamodule.train.std + datamodule.train.mean\n",
    "pred_df_ = pd.DataFrame({rnn_config.rnn_type: pred}, index=sample_test_df.index)\n",
    "pred_df = pred_df.join(pred_df_,lsuffix='_left', rsuffix='_right')\n",
    "metrics = calculate_metrics(sample_test_df[target], pred_df_[rnn_config.rnn_type], rnn_config.rnn_type, pd.concat([sample_train_df[target],sample_val_df[target]]))\n",
    "metric_record.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdd1f84-200e-4029-833e-b5e34e86a2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7836_row0_col4 {\n",
       "  color: black;\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_f7836_row2_col1, #T_f7836_row2_col2, #T_f7836_row2_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7836\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f7836_level0_col0\" class=\"col_heading level0 col0\" >Algorithm</th>\n",
       "      <th id=\"T_f7836_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_f7836_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_f7836_level0_col3\" class=\"col_heading level0 col3\" >MASE</th>\n",
       "      <th id=\"T_f7836_level0_col4\" class=\"col_heading level0 col4\" >Forecast Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7836_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f7836_row0_col0\" class=\"data row0 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_f7836_row0_col1\" class=\"data row0 col1\" >0.1598</td>\n",
       "      <td id=\"T_f7836_row0_col2\" class=\"data row0 col2\" >0.0743</td>\n",
       "      <td id=\"T_f7836_row0_col3\" class=\"data row0 col3\" >1.2452</td>\n",
       "      <td id=\"T_f7836_row0_col4\" class=\"data row0 col4\" >3.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7836_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f7836_row1_col0\" class=\"data row1 col0\" >XGB Random Forest</td>\n",
       "      <td id=\"T_f7836_row1_col1\" class=\"data row1 col1\" >0.1642</td>\n",
       "      <td id=\"T_f7836_row1_col2\" class=\"data row1 col2\" >0.0814</td>\n",
       "      <td id=\"T_f7836_row1_col3\" class=\"data row1 col3\" >1.2797</td>\n",
       "      <td id=\"T_f7836_row1_col4\" class=\"data row1 col4\" >8.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7836_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f7836_row2_col0\" class=\"data row2 col0\" >LightGBM</td>\n",
       "      <td id=\"T_f7836_row2_col1\" class=\"data row2 col1\" >0.1489</td>\n",
       "      <td id=\"T_f7836_row2_col2\" class=\"data row2 col2\" >0.0691</td>\n",
       "      <td id=\"T_f7836_row2_col3\" class=\"data row2 col3\" >1.1601</td>\n",
       "      <td id=\"T_f7836_row2_col4\" class=\"data row2 col4\" >3.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7836_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f7836_row3_col0\" class=\"data row3 col0\" >RNN</td>\n",
       "      <td id=\"T_f7836_row3_col1\" class=\"data row3 col1\" >0.1831</td>\n",
       "      <td id=\"T_f7836_row3_col2\" class=\"data row3 col2\" >0.0942</td>\n",
       "      <td id=\"T_f7836_row3_col3\" class=\"data row3 col3\" >1.4266</td>\n",
       "      <td id=\"T_f7836_row3_col4\" class=\"data row3 col4\" >12.95%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bf0dc87c10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted = pd.DataFrame(metric_record).style.format({\"MAE\": \"{:.4f}\", \n",
    "                          \"MSE\": \"{:.4f}\", \n",
    "                          \"MASE\": \"{:.4f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"})\n",
    "formatted.highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"MASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b0fda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[rnn_config.rnn_type], forecast_display_names=[rnn_config.rnn_type])\n",
    "fig = format_plot(fig, title=f\"{rnn_config.rnn_type}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_12/rnn.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b7c8a-47dd-42bd-ab4b-47ec08e48c99",
   "metadata": {},
   "source": [
    "# Running LSTMs and GRUs on a Sample Household"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225e1d2-e442-4fad-a1b2-e1c00fa94aa6",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5932400d-0be1-4dcc-b7fd-87e14daa3ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type    | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | rnn  | LSTM    | 924 K  | train\n",
      "1 | fc   | Linear  | 257    | train\n",
      "2 | loss | MSELoss | 0      | train\n",
      "-----------------------------------------\n",
      "924 K     Trainable params\n",
      "0         Non-trainable params\n",
      "924 K     Total params\n",
      "3.700     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db81db986ba04b689848120d534f847a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "rnn_config = SingleStepRNNConfig(\n",
    "    rnn_type=\"LSTM\",\n",
    "    input_size=1,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    bidirectional=True,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "model = SingleStepRNNModel(rnn_config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "   \n",
    "  \n",
    "    max_epochs=1,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor=\"valid_loss\", patience=3)],\n",
    ")\n",
    "trainer.fit(model, datamodule)\n",
    "# Removing artifacts created during training\n",
    "shutil.rmtree(\"lightning_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a1556e-23b8-4b94-9638-33baae755f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb7138647334c27a442f9770a0ccaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(model, datamodule.test_dataloader())\n",
    "# pred is a list of outputs, one for each batch\n",
    "pred = torch.cat(pred).squeeze().detach().numpy()\n",
    "# Apply reverse transformation because we applied global normalization\n",
    "pred = pred * datamodule.train.std + datamodule.train.mean\n",
    "pred_df_ = pd.DataFrame({rnn_config.rnn_type: pred}, index=sample_test_df.index)\n",
    "pred_df = pred_df.join(pred_df_)\n",
    "metrics = calculate_metrics(sample_test_df[target], pred_df_[rnn_config.rnn_type], rnn_config.rnn_type, pd.concat([sample_train_df[target],sample_val_df[target]]))\n",
    "metric_record.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7b7fd5a-4a39-4738-b588-ebdbe1b94d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_54fd3_row0_col4 {\n",
       "  color: black;\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_54fd3_row2_col1, #T_54fd3_row2_col2, #T_54fd3_row2_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_54fd3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_54fd3_level0_col0\" class=\"col_heading level0 col0\" >Algorithm</th>\n",
       "      <th id=\"T_54fd3_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_54fd3_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_54fd3_level0_col3\" class=\"col_heading level0 col3\" >MASE</th>\n",
       "      <th id=\"T_54fd3_level0_col4\" class=\"col_heading level0 col4\" >Forecast Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_54fd3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_54fd3_row0_col0\" class=\"data row0 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_54fd3_row0_col1\" class=\"data row0 col1\" >0.1598</td>\n",
       "      <td id=\"T_54fd3_row0_col2\" class=\"data row0 col2\" >0.0743</td>\n",
       "      <td id=\"T_54fd3_row0_col3\" class=\"data row0 col3\" >1.2452</td>\n",
       "      <td id=\"T_54fd3_row0_col4\" class=\"data row0 col4\" >3.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fd3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_54fd3_row1_col0\" class=\"data row1 col0\" >XGB Random Forest</td>\n",
       "      <td id=\"T_54fd3_row1_col1\" class=\"data row1 col1\" >0.1642</td>\n",
       "      <td id=\"T_54fd3_row1_col2\" class=\"data row1 col2\" >0.0814</td>\n",
       "      <td id=\"T_54fd3_row1_col3\" class=\"data row1 col3\" >1.2797</td>\n",
       "      <td id=\"T_54fd3_row1_col4\" class=\"data row1 col4\" >8.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fd3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_54fd3_row2_col0\" class=\"data row2 col0\" >LightGBM</td>\n",
       "      <td id=\"T_54fd3_row2_col1\" class=\"data row2 col1\" >0.1489</td>\n",
       "      <td id=\"T_54fd3_row2_col2\" class=\"data row2 col2\" >0.0691</td>\n",
       "      <td id=\"T_54fd3_row2_col3\" class=\"data row2 col3\" >1.1601</td>\n",
       "      <td id=\"T_54fd3_row2_col4\" class=\"data row2 col4\" >3.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fd3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_54fd3_row3_col0\" class=\"data row3 col0\" >RNN</td>\n",
       "      <td id=\"T_54fd3_row3_col1\" class=\"data row3 col1\" >0.1831</td>\n",
       "      <td id=\"T_54fd3_row3_col2\" class=\"data row3 col2\" >0.0942</td>\n",
       "      <td id=\"T_54fd3_row3_col3\" class=\"data row3 col3\" >1.4266</td>\n",
       "      <td id=\"T_54fd3_row3_col4\" class=\"data row3 col4\" >12.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_54fd3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_54fd3_row4_col0\" class=\"data row4 col0\" >LSTM</td>\n",
       "      <td id=\"T_54fd3_row4_col1\" class=\"data row4 col1\" >0.1722</td>\n",
       "      <td id=\"T_54fd3_row4_col2\" class=\"data row4 col2\" >0.0916</td>\n",
       "      <td id=\"T_54fd3_row4_col3\" class=\"data row4 col3\" >1.3423</td>\n",
       "      <td id=\"T_54fd3_row4_col4\" class=\"data row4 col4\" >15.04%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bf0f3316c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted = pd.DataFrame(metric_record).style.format({\"MAE\": \"{:.4f}\", \n",
    "                          \"MSE\": \"{:.4f}\", \n",
    "                          \"MASE\": \"{:.4f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"})\n",
    "formatted.highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"MASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3873b4f7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fig = plot_forecast(pred_df, forecast_columns=[rnn_config.rnn_type], forecast_display_names=[rnn_config.rnn_type])\n",
    "fig = format_plot(fig, title=f\"{rnn_config.rnn_type}: MAE: {metrics['MAE']:.4f} | MSE: {metrics['MSE']:.4f} | MASE: {metrics['MASE']:.4f} | Bias: {metrics['Forecast Bias']:.4f}\")\n",
    "fig.update_xaxes(type=\"date\", range=[\"2014-01-01\", \"2014-01-08\"])\n",
    "fig.write_image(\"imgs/chapter_12/lstm.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712bb0e-339d-471b-9ff3-82bd47bf8513",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3171dbf4-c053-4514-8ce0-0841b52e6167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type    | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | rnn  | GRU     | 693 K  | train\n",
      "1 | fc   | Linear  | 257    | train\n",
      "2 | loss | MSELoss | 0      | train\n",
      "-----------------------------------------\n",
      "693 K     Trainable params\n",
      "0         Non-trainable params\n",
      "693 K     Total params\n",
      "2.775     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7011695b894e66997a07b810e7dda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "rnn_config = SingleStepRNNConfig(\n",
    "    rnn_type=\"GRU\",\n",
    "    input_size=1,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    bidirectional=True,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "model = SingleStepRNNModel(rnn_config)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor=\"valid_loss\", patience=3)],\n",
    ")\n",
    "trainer.fit(model, datamodule)\n",
    "# Removing artifacts created during training\n",
    "shutil.rmtree(\"lightning_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4366e964-6565-47b4-b3d7-4c1330ca39af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4803612976a548cb968f3785620fd69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(model, datamodule.test_dataloader())\n",
    "# pred is a list of outputs, one for each batch\n",
    "pred = torch.cat(pred).squeeze().detach().numpy()\n",
    "# Apply reverse transformation because we applied global normalization\n",
    "pred = pred * datamodule.train.std + datamodule.train.mean\n",
    "pred_df_ = pd.DataFrame({rnn_config.rnn_type: pred}, index=sample_test_df.index)\n",
    "pred_df = pred_df.join(pred_df_)\n",
    "metrics = calculate_metrics(sample_test_df[target], pred_df_[rnn_config.rnn_type], rnn_config.rnn_type, pd.concat([sample_train_df[target],sample_val_df[target]]))\n",
    "metric_record.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a59cdc7-703b-4967-97cd-85787f4dc729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_70698_row0_col4 {\n",
       "  color: black;\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "#T_70698_row2_col1, #T_70698_row2_col2, #T_70698_row2_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_70698\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_70698_level0_col0\" class=\"col_heading level0 col0\" >Algorithm</th>\n",
       "      <th id=\"T_70698_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_70698_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_70698_level0_col3\" class=\"col_heading level0 col3\" >MASE</th>\n",
       "      <th id=\"T_70698_level0_col4\" class=\"col_heading level0 col4\" >Forecast Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_70698_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_70698_row0_col0\" class=\"data row0 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_70698_row0_col1\" class=\"data row0 col1\" >0.1598</td>\n",
       "      <td id=\"T_70698_row0_col2\" class=\"data row0 col2\" >0.0743</td>\n",
       "      <td id=\"T_70698_row0_col3\" class=\"data row0 col3\" >1.2452</td>\n",
       "      <td id=\"T_70698_row0_col4\" class=\"data row0 col4\" >3.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70698_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_70698_row1_col0\" class=\"data row1 col0\" >XGB Random Forest</td>\n",
       "      <td id=\"T_70698_row1_col1\" class=\"data row1 col1\" >0.1642</td>\n",
       "      <td id=\"T_70698_row1_col2\" class=\"data row1 col2\" >0.0814</td>\n",
       "      <td id=\"T_70698_row1_col3\" class=\"data row1 col3\" >1.2797</td>\n",
       "      <td id=\"T_70698_row1_col4\" class=\"data row1 col4\" >8.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70698_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_70698_row2_col0\" class=\"data row2 col0\" >LightGBM</td>\n",
       "      <td id=\"T_70698_row2_col1\" class=\"data row2 col1\" >0.1489</td>\n",
       "      <td id=\"T_70698_row2_col2\" class=\"data row2 col2\" >0.0691</td>\n",
       "      <td id=\"T_70698_row2_col3\" class=\"data row2 col3\" >1.1601</td>\n",
       "      <td id=\"T_70698_row2_col4\" class=\"data row2 col4\" >3.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70698_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_70698_row3_col0\" class=\"data row3 col0\" >RNN</td>\n",
       "      <td id=\"T_70698_row3_col1\" class=\"data row3 col1\" >0.1831</td>\n",
       "      <td id=\"T_70698_row3_col2\" class=\"data row3 col2\" >0.0942</td>\n",
       "      <td id=\"T_70698_row3_col3\" class=\"data row3 col3\" >1.4266</td>\n",
       "      <td id=\"T_70698_row3_col4\" class=\"data row3 col4\" >12.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70698_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_70698_row4_col0\" class=\"data row4 col0\" >LSTM</td>\n",
       "      <td id=\"T_70698_row4_col1\" class=\"data row4 col1\" >0.1722</td>\n",
       "      <td id=\"T_70698_row4_col2\" class=\"data row4 col2\" >0.0916</td>\n",
       "      <td id=\"T_70698_row4_col3\" class=\"data row4 col3\" >1.3423</td>\n",
       "      <td id=\"T_70698_row4_col4\" class=\"data row4 col4\" >15.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70698_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_70698_row5_col0\" class=\"data row5 col0\" >GRU</td>\n",
       "      <td id=\"T_70698_row5_col1\" class=\"data row5 col1\" >0.1793</td>\n",
       "      <td id=\"T_70698_row5_col2\" class=\"data row5 col2\" >0.0896</td>\n",
       "      <td id=\"T_70698_row5_col3\" class=\"data row5 col3\" >1.3971</td>\n",
       "      <td id=\"T_70698_row5_col4\" class=\"data row5 col4\" >4.55%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2bf0dc63760>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted = pd.DataFrame(metric_record).style.format({\"MAE\": \"{:.4f}\", \n",
    "                          \"MSE\": \"{:.4f}\", \n",
    "                          \"MASE\": \"{:.4f}\", \n",
    "                          \"Forecast Bias\": \"{:.2f}%\"})\n",
    "formatted.highlight_min(color='lightgreen', subset=[\"MAE\",\"MSE\",\"MASE\"]).apply(highlight_abs_min, props='color:black;background-color:lightgreen', axis=0, subset=['Forecast Bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9c838",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c6949ad",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dbe885c-dec2-415e-8291-f608d09cfd0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\london_smart_meters\\\\output\\\\dl_single_step_metrics_val_df_MAC000193.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.to_pickle(output/\"dl_single_step_prediction_val_df_MAC000193.pkl\")\n",
    "joblib.dump(metric_record, output/\"dl_single_step_metrics_val_df_MAC000193.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c63cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
